{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04fd1285",
   "metadata": {},
   "source": [
    "#### Q1. What is the mathematical formula for a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4e82d",
   "metadata": {},
   "source": [
    "The mathematical formula for a linear Support Vector Machine (SVM) can be expressed as follows:\n",
    "\n",
    "For classification:\n",
    "\n",
    "- y = sign(w·x + b),\n",
    "\n",
    "where x represents the input variables, w is the weight vector perpendicular to the hyperplane, ' · 'denotes the dot product, b is the bias term, and y takes values of either -1 or +1, representing the two classes.\n",
    "\n",
    "In equation form:\n",
    "\n",
    "yi = sign(w·xi + b),\n",
    "\n",
    "where (xi, yi) are the training examples.\n",
    "\n",
    "The goal of SVM is to find the optimal weight vector w and bias term b that minimize the misclassification errors while maximizing the margin between classes. The optimization problem involves solving for w and b that satisfy certain constraints, which ensure correct classification and margin maximization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2d1b8f",
   "metadata": {},
   "source": [
    "#### Q2. What is the objective function of a linear SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566a852",
   "metadata": {},
   "source": [
    "The objective function of a linear Support Vector Machine (SVM) is to find the optimal hyperplane that maximizes the margin between the classes while minimizing the classification error. The objective function can be written as:\n",
    "\n",
    "Minimize: 1/2*||w||^2,\n",
    "\n",
    "Subject to: yi(w · xi + b) ≥ 1,\n",
    "\n",
    "where (xi, yi) are the training examples, w is the weight vector perpendicular to the hyperplane, · denotes the dot product, b is the bias term, ||w||^2 represents the regularization term, and yi takes values of either -1 or +1, representing the two classes.\n",
    "\n",
    "The objective function aims to minimize the norm of the weight vector, which corresponds to the complexity of the model, while satisfying the constraint that all training examples lie on the correct side of the decision boundary with a margin of at least 1. The constraint ensures that the SVM achieves good generalization and separates the classes accurately.\n",
    "\n",
    "The objective function of a linear SVM can be optimized using various optimization techniques, such as quadratic programming or gradient descent, to find the optimal values of the weight vector w and bias term b that fulfill the margin and classification constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bbc88a",
   "metadata": {},
   "source": [
    "#### Q3. What is the kernel trick in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ed024",
   "metadata": {},
   "source": [
    "The kernel trick is a technique used in Support Vector Machines (SVM) that allows them to handle non-linearly separable data without explicitly transforming the input data into a higher-dimensional feature space. It enables SVM to efficiently compute the decision boundary and make predictions based on the transformed feature space without explicitly calculating the transformed feature vectors.\n",
    "\n",
    "In traditional SVM, the decision boundary is determined by the dot product of the input feature vectors. However, when dealing with complex, non-linear relationships, it may be difficult to find a linear decision boundary in the original feature space.\n",
    "\n",
    "The kernel trick solves this problem by introducing a kernel function, denoted as K(x_i, x_j), which calculates the dot product between the transformed feature vectors in a higher-dimensional space. This allows SVM to implicitly map the input data into a higher-dimensional feature space where it might be linearly separable.\n",
    "\n",
    "By using the kernel function, the SVM algorithm can compute the decision boundary in the transformed feature space without explicitly calculating the transformed feature vectors. This approach saves computational resources and avoids the need to define the transformation explicitly.\n",
    "\n",
    "Commonly used kernel functions include:\n",
    "\n",
    "- Linear Kernel: K(xi, xj) = xi · xj, which is equivalent to the standard dot product between the original feature vectors.\n",
    "- Polynomial Kernel: K(xi, xj) = (γ(xi · xj) + r)^d, where γ, r, and d are kernel parameters.\n",
    "- Radial Basis Function (RBF) Kernel: K(xi, xj) = exp(-γ ||xi - xj||^2), where γ is a kernel parameter that controls the smoothness of the decision boundary.\n",
    "- Sigmoid Kernel: K(xi, xj) = tanh(γ(xi · xj) + r), where γ and r are kernel parameters.\n",
    "\n",
    "By selecting an appropriate kernel function, SVM can effectively handle non-linear decision boundaries and capture complex relationships between the input variables, allowing for more accurate classification or regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d087d2cc",
   "metadata": {},
   "source": [
    "#### Q4. What is the role of support vectors in SVM Explain with example "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ebfa40",
   "metadata": {},
   "source": [
    "Support vectors play a crucial role in Support Vector Machines (SVM). They are the training examples that are closest to the decision boundary or lie within the margin. In SVM, the decision boundary is determined by these support vectors.\n",
    "\n",
    "To explain the role of support vectors, let's consider a simple example. Suppose we have a binary classification problem with two classes, represented by red and blue data points in a two-dimensional space.\n",
    "\n",
    "In SVM, the algorithm aims to find the optimal decision boundary, also known as the hyperplane, that separates these two classes. The hyperplane is defined by a weight vector w and a bias term b.\n",
    "\n",
    "During the training process, SVM identifies the support vectors, which are the data points closest to the decision boundary. These support vectors have a significant influence on determining the position and orientation of the decision boundary.\n",
    "\n",
    "The support vectors are the critical data points because they define the margin. The margin is the region between the two parallel hyperplanes, one for each class, that are maximally distant from each other while not including any data points.\n",
    "\n",
    "The support vectors lie on or within the margin boundaries. They are the data points that have the potential to affect the decision boundary if their positions change. Other data points that are not support vectors do not affect the decision boundary since they do not lie on or within the margin.\n",
    "\n",
    "The importance of support vectors lies in their influence on the SVM model's generalization performance. By focusing on the support vectors, SVM effectively handles the training data and builds a decision boundary that is less sensitive to outliers and noise. This property leads to a more robust and accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6272096",
   "metadata": {},
   "source": [
    "#### Q5. Illustrate with examples and graphs of Hyperplane, Marginal plane, Soft margin and Hard margin in SVM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f41f7",
   "metadata": {},
   "source": [
    "Certainly! Let's illustrate the concepts of the hyperplane, marginal plane, soft margin, and hard margin in SVM with examples and graphs.\n",
    "\n",
    "- Hyperplane: The hyperplane is the decision boundary that separates the classes in SVM. In a binary classification problem with two input features, the hyperplane is a line. In a three-dimensional space with three input features, the hyperplane is a plane.\n",
    "\n",
    "Example: Consider a simple example with two classes, represented by red and blue points. The graph below shows a linear hyperplane (a line) that separates the classes. The hyperplane is denoted by the black line.\n",
    "\n",
    "\n",
    "- Margin: The margin is the region between the two parallel planes/hyperplanes that are maximally distant from each other while not including any data points. It is defined by the support vectors, which are the data points lying on or within the margin boundaries.\n",
    "\n",
    "Example: The graph below shows a linear SVM with the margin denoted by the shaded region. The support vectors are the points on or within the margin boundaries (highlighted by circles).\n",
    "\n",
    "\n",
    "- Hard Margin: In a hard margin SVM, the goal is to find a hyperplane that perfectly separates the classes without allowing any misclassifications. This approach assumes that the data is linearly separable without any overlapping points.\n",
    "\n",
    "Example: The graph below illustrates a hard margin SVM with a linearly separable dataset. The hyperplane perfectly separates the red and blue points without any misclassifications.\n",
    "\n",
    "\n",
    "- Soft Margin: In a soft margin SVM, a certain amount of misclassification is allowed to find a hyperplane that separates the classes while allowing for some tolerance for errors. Soft margin SVMs are used when the data points are not linearly separable or when dealing with noisy datasets.\n",
    "\n",
    "Example: The graph below depicts a soft margin SVM with a linearly non-separable dataset. The misclassified points, denoted by the circles, are allowed within the margin, resulting in a more flexible decision boundary.\n",
    "\n",
    "\n",
    "The examples and graphs above demonstrate the concepts of the hyperplane, marginal plane, soft margin, and hard margin in SVM. They showcase different scenarios in SVM, from perfectly separable data with a hard margin to non-separable data with a soft margin that allows for misclassifications within the margin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c38635",
   "metadata": {},
   "source": [
    "#### Q6. SVM Implementation through Iris dataset.\n",
    "\n",
    "Bonus task: Implement a linear SVM classifier from scratch using Python and compare its\n",
    "performance with the scikit-learn implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716925bb",
   "metadata": {},
   "source": [
    "- Load the iris dataset from the scikit-learn library and split it into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f6ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60964457",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23148a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de9f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47367cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, train_size=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b90de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width\n",
       "91           6.1          3.0           4.6          1.4\n",
       "41           4.5          2.3           1.3          0.3\n",
       "58           6.6          2.9           4.6          1.3\n",
       "90           5.5          2.6           4.4          1.2\n",
       "48           5.3          3.7           1.5          0.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c43b84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91    versicolor\n",
       "41        setosa\n",
       "58    versicolor\n",
       "90    versicolor\n",
       "48        setosa\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1dee09",
   "metadata": {},
   "source": [
    "#### - Train a linear SVM classifier on the training set and predict the labels for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "446a9b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de72ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81bc5619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb6853d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04640291,  0.25102128, -0.88984179, -0.37711427],\n",
       "       [ 0.05546538,  0.12007903, -0.52236181, -0.2676029 ],\n",
       "       [ 0.69910361,  0.17726741, -1.58142662, -1.15508309]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a99673b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1996791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae475c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        43\n",
      "  versicolor       1.00      0.92      0.96        39\n",
      "   virginica       0.93      1.00      0.96        38\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.98      0.97      0.97       120\n",
      "weighted avg       0.98      0.97      0.97       120\n",
      "\n",
      "[[43  0  0]\n",
      " [ 0 36  3]\n",
      " [ 0  0 38]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8056495e",
   "metadata": {},
   "source": [
    "#### - Compute the accuracy of the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4892e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4690e",
   "metadata": {},
   "source": [
    "#### - Plot the decision boundaries of the trained model using two of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc3e1b",
   "metadata": {},
   "source": [
    "#### - Try different values of the regularisation parameter C and see how it affects the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05f6868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e1a54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e616358",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(SVC(), param_grid = param_grid, refit= True , cv = 5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfa789bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV 1/5] END .............................C=0.1;, score=0.333 total time=   0.0s\n",
      "[CV 2/5] END .............................C=0.1;, score=0.333 total time=   0.0s\n",
      "[CV 3/5] END .............................C=0.1;, score=0.333 total time=   0.0s\n",
      "[CV 4/5] END .............................C=0.1;, score=0.667 total time=   0.0s\n",
      "[CV 5/5] END .............................C=0.1;, score=0.667 total time=   0.0s\n",
      "[CV 1/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ...............................C=1;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ...............................C=1;, score=0.833 total time=   0.0s\n",
      "[CV 5/5] END ...............................C=1;, score=0.833 total time=   0.0s\n",
      "[CV 1/5] END ..............................C=10;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ..............................C=10;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ..............................C=10;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ..............................C=10;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ..............................C=10;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END .............................C=100;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END .............................C=100;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END .............................C=100;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END .............................C=100;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END .............................C=100;, score=1.000 total time=   0.0s\n",
      "[CV 1/5] END ............................C=1000;, score=1.000 total time=   0.0s\n",
      "[CV 2/5] END ............................C=1000;, score=1.000 total time=   0.0s\n",
      "[CV 3/5] END ............................C=1000;, score=1.000 total time=   0.0s\n",
      "[CV 4/5] END ............................C=1000;, score=1.000 total time=   0.0s\n",
      "[CV 5/5] END ............................C=1000;, score=1.000 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(), param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(), param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), param_grid={'C': [0.1, 1, 10, 100, 1000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b620baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "\n",
    "y_pred2 = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85b7c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        43\n",
      "  versicolor       1.00      0.95      0.97        39\n",
      "   virginica       0.95      1.00      0.97        38\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "[[43  0  0]\n",
      " [ 0 37  2]\n",
      " [ 0  0 38]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))\n",
    "print(confusion_matrix(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "95cac045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5f69b",
   "metadata": {},
   "source": [
    "Interpretation: We can clearly see that using gridsearch cv for C parameter our model accuracy increase from 97.5 to 98.33."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
