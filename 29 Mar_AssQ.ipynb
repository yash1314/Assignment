{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ece2f1",
   "metadata": {},
   "source": [
    "#### Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088ada7",
   "metadata": {},
   "source": [
    "Lasso regression is a regularization technique. Lasso regression is used to overcome multicollinearity and overfitting of model. It is also used to perform feature selection/parameter elimination. It gives more accurate prediction and sparse model over linear regression. It shrink data points coefficients towards zero to achieve simple and sparse model. This leads to minimum effect of predicators variables over output variables. \n",
    "\n",
    "Lasso uses L1 regularization. It adds penalty factor to the loss function which leads to less variance and shrinkage of data points (feature selection). Feature selection is achieved by shrinking data points coefficients towards zero or equal to zero which reduces the overall effect of particular variable.\n",
    "\n",
    "Formula: \n",
    "\n",
    "lasso_loss_fun = SSR + lambda*(absolute sum of coefficients (slope) of variables)\n",
    "\n",
    "- If the value of lambda is much greater than the value of coefficients tends to reach zero. This eliminates unnecessary features or variables. \n",
    "\n",
    "- Other regression techniques uses different loss_fuction than lasso loss_function which is L1 regularization. Ridge regression uses L2 regularization while simple linear regression uses OLS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b56bc",
   "metadata": {},
   "source": [
    "#### Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d74b65",
   "metadata": {},
   "source": [
    "The main advantage of lasso regression in feature selection is it automates the process of feature elimination. It has the ability to set the coefficients for features it does not consider interesting set to zero. This is automatically done by lasso which is best advantage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc88d4b",
   "metadata": {},
   "source": [
    "#### Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff176d72",
   "metadata": {},
   "source": [
    "Coefficients denotes the change in the output i.e target variables and it also denotes the direction of change through signs. In lasso regression model we have a penalty in loss_function. This penalty factor penalizes high coefficients by shrinking them toward zero. This is done through a peanlty factor called lambda. If the value for lambda is set too high, the coefficients moves towards zero. This in turn leads to variable elimination/ feature selection. Those coefficients which are non-zero are then used to check the effectiveness of regularization model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fda7cd",
   "metadata": {},
   "source": [
    "#### Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c95434",
   "metadata": {},
   "source": [
    "The lambda which is penalty factor in lasso regression is the tuning parameter. By changing its value we can adjust the numbers of slopes/coefficients reaching zero. High value of Lambda leads to our target variable getting unaffected by change in intput variable.\n",
    "\n",
    "- If the value of lambda in lasso regularization is too small then very less coefficients will reach toward zero.\n",
    "\n",
    "- If the value of lambda is too too high then maximum coefficients which are least significant will reach towards zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279aa535",
   "metadata": {},
   "source": [
    "#### Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d43b18",
   "metadata": {},
   "source": [
    "No, in general we cannot use lasso for non-linear regression problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6591005b",
   "metadata": {},
   "source": [
    "#### Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8e89c",
   "metadata": {},
   "source": [
    "- Ridge regression and lasso regression are both regularization techniques.\n",
    "- Ridge regression is l2 regularization whereas lasso is l1 regularization.\n",
    "- Ridge regression uses sum of square of magnitude of coefficients along with penatly factor lambda to perfrom L2 regularization. whereas lasso regression uses sum of absolute value of coefficients along with penalty factor lambda to perform l1 regularization.\n",
    "- Ridge regression only deals with multicollinearity and overfitting, it dosen't perfrom feature selection whereas lasso regression deals with overfitting as well as performs feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a8481",
   "metadata": {},
   "source": [
    "#### Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec05b28",
   "metadata": {},
   "source": [
    "Yes, lasso regression can handle multicollinearity. Lasso uses l1 regularization which adds penatly factor lambda as well as sum of absolute magnitude of coefficients to loss_function. We tune tuning parameter lambda which penalize coefficients. Some coefficients which are insignificant and have collinearity tends to reach towards zero when we tune lambda parameter. This reduces/eliminate coefficient which have collinearity and non-zero coefficients contributes to estimating models performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b93d80",
   "metadata": {},
   "source": [
    "#### Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d11f32",
   "metadata": {},
   "source": [
    "we choose the optimal value of lambda factor through cross-validation and inparticular 10 Fold cross-validatioin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
