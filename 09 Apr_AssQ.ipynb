{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1afe08",
   "metadata": {},
   "source": [
    "#### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e5a86",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental concept in probability theory and statistics, named after the Reverend Thomas Bayes. It provides a way to update our beliefs about an event or hypothesis based on new evidence. Mathematically, Bayes' theorem is expressed as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "Where:\n",
    "\n",
    "P(A|B) : is the probability of event A occurring given that event B has occurred (called the posterior probability).\n",
    "\n",
    "P(B|A) : is the probability of event B occurring given that event A has occurred (called the likelihood).\n",
    "\n",
    "P(A) : is the prior probability of event A occurring before considering any evidence.\n",
    "\n",
    "P(B) : is the probability of event B occurring (also known as the evidence or marginal likelihood).\n",
    "\n",
    "In words, Bayes' theorem states that the posterior probability of event A occurring, given evidence B, is proportional to the likelihood of event B occurring given event A, multiplied by the prior probability of event A, divided by the probability of event B occurring.\n",
    "\n",
    "This theorem provides a formal way to update our beliefs or probabilities based on new information. It is widely used in various fields, including machine learning, data science, and Bayesian statistics, to reason about uncertain events and make informed decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcfb69",
   "metadata": {},
   "source": [
    "#### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d2bf9e",
   "metadata": {},
   "source": [
    "The theorem is mathematically stated as follows:\n",
    "\n",
    "P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "In this equation:\n",
    "\n",
    "P(A|B) represents the conditional probability of event A occurring given that event B has already occurred.\n",
    "\n",
    "P(B|A) is the conditional probability of event B occurring given that event A has already occurred.\n",
    "\n",
    "P(A) and P(B) are the probabilities of event A and event B occurring independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062207ae",
   "metadata": {},
   "source": [
    "#### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1af9c8",
   "metadata": {},
   "source": [
    "AnS: Bayes' theorem is used in various practical applications across different fields. Here are a few examples:\n",
    "\n",
    "Medical Diagnosis: Bayes' theorem is utilized in medical diagnosis to assess the probability of a particular disease or condition given certain symptoms. Doctors can combine prior knowledge (prevalence of the disease) with the observed symptoms to calculate the probability of a correct diagnosis.\n",
    "\n",
    "Spam Filtering: Email spam filters often employ Bayes' theorem to classify incoming emails as either spam or legitimate. The filter calculates the probability of an email being spam or not based on the occurrence of specific words or patterns in the email content, using previously collected data on spam and non-spam emails.\n",
    "\n",
    "Risk Assessment: Bayes' theorem is used in risk assessment and decision-making processes. By incorporating prior knowledge and available evidence, it helps evaluate the probability of potential risks and make informed decisions based on updated probabilities.\n",
    "\n",
    "Machine Learning: Bayes' theorem serves as a foundation for Bayesian machine learning methods. Bayesian models utilize prior probabilities and update them with observed data to make predictions or estimate parameters in a probabilistic manner. It provides a framework for learning and updating beliefs based on new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05524907",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31884b",
   "metadata": {},
   "source": [
    "Ans: Bayes' theorem provides a mathematical relationship between conditional probabilities, allowing us to update our beliefs or knowledge about the likelihood of an event A happening given new evidence or information B. It establishes a connection between the conditional probability P(A|B) and other conditional probabilities such as P(B|A), P(A), and P(B). By using Bayes' theorem, we can calculate the probability of A given B by multiplying the conditional probability of B given A by the prior probability of A and dividing it by the prior probability of B.\n",
    "\n",
    "Conditional probability, on the other hand, refers to the probability of an event occurring given that another event has already occurred. It is denoted as P(A|B), where A and B are two events. Conditional probability allows us to assess the likelihood of A happening given the occurrence of B. It forms the basis of Bayes' theorem, where the conditional probability P(A|B) is the key quantity to be calculated. Bayes' theorem provides a framework to update our understanding of the conditional probability P(A|B) based on known probabilities P(B|A), P(A), and P(B). It enables us to incorporate new evidence (P(B|A)) into our initial belief (P(A)) and determine the revised probability of A given B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80119d",
   "metadata": {},
   "source": [
    "#### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def86b7",
   "metadata": {},
   "source": [
    "Ans: When choosing a type of Naive Bayes classifier for a given problem, the decision is typically based on the specific characteristics of the problem and the assumptions that are most appropriate. Here are some considerations to guide the selection process:\n",
    "\n",
    "Multinomial Naive Bayes: This classifier is suitable for problems involving discrete features, such as text categorization or document classification. It assumes that the features follow a multinomial distribution, and it works well with features represented by frequency counts or occurrence rates.\n",
    "\n",
    "Bernoulli Naive Bayes: If the features are binary or represent presence/absence of certain characteristics, the Bernoulli Naive Bayes classifier is a good choice. It assumes that the features are generated from a Bernoulli distribution and works well for problems like text classification with binary feature representations.\n",
    "\n",
    "Gaussian Naive Bayes: This classifier is appropriate when dealing with continuous features that can be modeled using a Gaussian (normal) distribution. It assumes that the features within each class follow a Gaussian distribution with mean and variance estimated from the training data. Gaussian Naive Bayes is commonly used in problems where numerical attributes are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e40136",
   "metadata": {},
   "source": [
    "#### Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features   X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "Class\t X1=1 X1=2 \tX1=3 \tX2=1 \tX2=2 \tX2=3\t X2=4\n",
    "\n",
    " A\t     3\t  3\t    4\t    4\t    3\t    3\t     3\n",
    "\n",
    " B\t     2\t  2\t    1\t    2\t    2\t    2\t     3\n",
    "\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c452dc",
   "metadata": {},
   "source": [
    "Ans: \n",
    "\n",
    "1) Calculate the prior probabilities (assuming equal priors for each class):\n",
    "\n",
    "P(A) = P(B) = 0.5\n",
    "\n",
    "2) Calculate the likelihoods for each feature value given each class:\n",
    "P(X1 = 3 | A) = 4 / 16 = 0.25\n",
    "\n",
    "P(X1 = 3 | B) = 1 / 12 ≈ 0.083\n",
    "\n",
    "P(X2 = 4 | A) = 3 / 16 = 0.188\n",
    "\n",
    "P(X2 = 4 | B) = 3 / 12 = 0.25\n",
    "\n",
    "3) Calculate the probability of the new instance for each class using the naive assumption of independence:\n",
    "P(X1 = 3, X2 = 4 | A) = P(X1 = 3 | A) * P(X2 = 4 | A) ≈ 0.25 * 0.188 ≈ 0.047\n",
    "\n",
    "P(X1 = 3, X2 = 4 | B) = P(X1 = 3 | B) * P(X2 = 4 | B) ≈ 0.083 * 0.25 ≈ 0.021\n",
    "\n",
    "4) Apply Bayes' theorem to calculate the posterior probabilities:\n",
    "P(A | X1 = 3, X2 = 4) = (P(X1 = 3, X2 = 4 | A) * P(A)) / P(X1 = 3, X2 = 4)\n",
    "\n",
    "P(B | X1 = 3, X2 = 4) = (P(X1 = 3, X2 = 4 | B) * P(B)) / P(X1 = 3, X2 = 4)\n",
    "\n",
    "Since the denominators P(X1 = 3, X2 = 4) are the same for both classes, we can compare the numerators directly:\n",
    "\n",
    "Numerator for class A: P(X1 = 3, X2 = 4 | A) * P(A) ≈ 0.047 * 0.5 ≈ 0.0235\n",
    "\n",
    "Numerator for class B: P(X1 = 3, X2 = 4 | B) * P(B) ≈ 0.021 * 0.5 = 0.0105\n",
    "\n",
    "- Comparing the numerator we can see that the numerator for class A is larger than that for class B. Therefore, according to Naive Bayes the new instance with features X1 = 3 and X2 = 4 would be predicted to belong to class A."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
